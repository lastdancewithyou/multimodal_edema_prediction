import os
import numpy as np
from scipy.optimize import linear_sum_assignment

import torch
import torch.distributed as dist
import torch.nn as nn
import torch.nn.functional as F

from training.run import parse_arguments
from utils import timer
from loss.target_generation import generate_optimal_target


OUTPUT_DIR = "/home/DAHS1/gangmin/my_research/clinical_multimodal_learning/output/"


class MultiModalLoss(nn.Module):
    """
    - Lossë“¤ì„ ê´€ë¦¬í•˜ëŠ” ìµœìƒìœ„ ëª¨ë“ˆ
    - í˜„ì¬ëŠ” ë¼ë²¨ ì—†ëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” LossëŠ” í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŒ.
    """
    def __init__(self, args, class_weights=None):
        super().__init__()

        self.num_classes = args.num_classes
        self.use_label_smooth = args.use_label_smooth
        self.label_smoothing = args.label_smoothing
        amp_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

        # ==================== CE Loss ====================
        if class_weights is not None:
            print("[Loss] Using class weights for CE Loss")
            self.class_weights = class_weights.to(dtype=amp_dtype)

            # label smoothing
            if self.use_label_smooth:
                self.ce_loss = nn.CrossEntropyLoss(weight=self.class_weights.float(), ignore_index=-1, label_smoothing=self.label_smoothing)
                print(f"[Loss] CE Loss with label smoothing (factor={self.label_smoothing})")
            else:
                self.ce_loss = nn.CrossEntropyLoss(weight=self.class_weights.float(), ignore_index=-1)
                print(f"[Loss] Standard CE Loss with class weights")
        
        # CE loss without class weights (í˜„ì¬ëŠ” ì‚¬ìš©í•˜ê³  ìˆì§€ ì•ŠìŒ.)
        else:
            print("[Loss] CE Loss without class weights")
            if self.use_label_smooth:
                self.ce_loss = nn.CrossEntropyLoss(ignore_index=-1, label_smoothing=self.label_smoothing)
                print(f"[Loss] CE Loss with label smoothing (factor={self.label_smoothing})")
            else:
                self.ce_loss = nn.CrossEntropyLoss(ignore_index=-1)
                print(f"[Loss] Standard CE Loss")

        # ==================== Supervised Contrastive Loss ====================
        self.use_supcon = args.use_supcon
        if self.use_supcon:
            self.supcon_loss_fn = SupConLoss()
            self.scl_temperature = args.scl_temperature
            print(f"[Loss] Supervised Contrastive Loss enabled (temperature={self.scl_temperature})")
        else:
            self.supcon_loss_fn = None
            print(f"[Loss] Supervised Contrastive Loss disabled")

        # ==================== Target_SupCon Loss (TSC + KCL) ====================
        self.use_target_supcon = args.use_target_supcon
        if self.use_target_supcon:
            self.target_supcon_loss_fn = TSCwithQueue(
                args=args,
                embedding_dim=args.head_hidden_dim2,
                queue_size=args.target_supcon_queue_size,
                n_cls=args.num_classes,
                T=args.target_supcon_temperature,
                num_positive=args.target_supcon_K,
                targeted=True,
                tr=args.target_supcon_tr,
                sep_t=True,
                tw=args.target_supcon_tw
            )
            print(f"[Loss] TSCwithQueue Loss enabled")
            print(f"       - Queue Size: {args.target_supcon_queue_size}")
            print(f"       - Temperature: {args.target_supcon_temperature}")
            print(f"       - K (max positives): {args.target_supcon_K}")
            print(f"       - TSC Weight (tw): {args.target_supcon_tw}")
            print(f"       - Embedding Dim: {args.head_hidden_dim2}")
        else:
            self.target_supcon_loss_fn = None
            print(f"[Loss] TSCwithQueue Loss disabled")

    def cross_entropy(self, logits, labels):
        # logits: [B, W, num_classes]
        # labels: [B, W]
        logits_flat = logits.view(-1, logits.size(-1)).float()
        labels_flat = labels.view(-1).long()                    
        ce_loss = self.ce_loss(logits_flat, labels_flat)
        return ce_loss

    def forward(self, classification_input, seq_valid_mask, logits, labels, window_mask, stay_ids, device,
                ce_weight=0.0, scl_weight=0.0,
                target_supcon_weight=0.0, 
                # window_time_indices=None, 
                accelerator=None,
                projected_embeddings_multiview=None, current_epoch=None, total_epochs=None):

        # -------------------- (1) CE Loss --------------------
        if ce_weight > 0.0:
            with timer("CE Loss", accelerator):
                ce_loss = self.cross_entropy(logits, labels)
        else:
            ce_loss = torch.tensor(0.0, device=device, requires_grad=False)

        # -------------------- (2) Supervised Contrastive Loss --------------------
        if self.use_supcon and scl_weight > 0.0:
            with timer("Supervised Contrastive Loss", accelerator):
                supcon_input = projected_embeddings_multiview if projected_embeddings_multiview is not None else classification_input
                scl_loss = self.supcon_loss_fn(
                    embeddings=supcon_input,
                    labels=labels,
                    window_mask=window_mask,
                    temperature=self.scl_temperature
                )
        else:
            scl_loss = torch.tensor(0.0, device=device, requires_grad=False)

        # -------------------- (2-1) Target_SupCon Loss (KCL + TSC) --------------------
        if self.use_target_supcon and target_supcon_weight > 0.0 and projected_embeddings_multiview is not None:
            with timer("Target_SupCon Loss", accelerator):
                # Multi-view projections: [Nwin, 2, D]
                z_view0 = projected_embeddings_multiview[:, 0, :]  # [Nwin, D]
                z_view1 = projected_embeddings_multiview[:, 1, :]  # [Nwin, D]

                B, W = labels.shape
                labels_flat = labels.reshape(B * W)
                mask_flat = window_mask.reshape(B * W).bool()
                labels_valid = labels_flat[mask_flat]  # [Nwin]

                # Filter out -1 labels (unlabeled samples)
                labeled_mask = (labels_valid != -1)                 # [Nwin]
                z_view0_labeled = z_view0[labeled_mask]             # [N_labeled, D]
                z_view1_labeled = z_view1[labeled_mask]             # [N_labeled, D]
                labels_labeled = labels_valid[labeled_mask]         # [N_labeled] - no -1

                # TSCwithQueue forward: (v, v_tilde, y, update_queue)
                loss_dict = self.target_supcon_loss_fn(
                    v=z_view0_labeled,
                    v_tilde=z_view1_labeled,
                    y=labels_labeled,
                    update_queue=True,
                    current_epoch=current_epoch,
                    total_epochs=total_epochs,
                )

                target_supcon_loss = loss_dict["loss"]  # KCL + TSC combined
                loss_kcl = loss_dict["loss_kcl"]        # KCL only (for logging)
                loss_tsc = loss_dict["loss_tsc"]        # TSC only (for logging)

        else:
            target_supcon_loss = torch.tensor(0.0, device=device, requires_grad=False)
            loss_kcl = torch.tensor(0.0, device=device, requires_grad=False)
            loss_tsc = torch.tensor(0.0, device=device, requires_grad=False)

        # -------------------- NaN Detection --------------------
        if torch.isnan(ce_loss) or torch.isinf(ce_loss):
            print(f"[WARNING] CE Loss is NaN/Inf: {ce_loss.item()}")

        if torch.isnan(scl_loss) or torch.isinf(scl_loss):
            print(f"[WARNING] SCL Loss is NaN/Inf: {scl_loss.item()}")

        if torch.isnan(target_supcon_loss) or torch.isinf(target_supcon_loss):
            print(f"[WARNING] Target_SupCon Loss is NaN/Inf: {target_supcon_loss.item()}")

        # -------------------- Total Loss --------------------
        total_loss = (
            ce_weight * ce_loss +
            scl_weight * scl_loss +
            target_supcon_weight * target_supcon_loss  # KCL + TSC combined
        )

        return total_loss, ce_loss, scl_loss, target_supcon_loss, loss_kcl, loss_tsc
    
    # validation & test
    def inference(self, classification_input, logits, labels, window_mask):
        return {
            'logits': logits,
            'labels': labels,
            'window_mask': window_mask,
            'window_embeddings': classification_input
        }


class TSCwithQueue(nn.Module):
    """
    - Lossì™€ Queueë¥¼ ê´€ë¦¬í•˜ëŠ” ìµœìƒìœ„ ëª¨ë“ˆ
    """
    def __init__(self, args, embedding_dim=128, queue_size=8192, n_cls=3, T=0.07, num_positive=6, targeted=True, tr=1, sep_t=True, tw=1.0):
        super().__init__()
        
        self.queue = TSCQueue(
            embedding_dim=embedding_dim,
            queue_size=queue_size,
        )

        self.kcl = KCL(
            dim=embedding_dim,
            K=queue_size,
            T=T,
            num_positive=num_positive,
            targeted=targeted,
            tr=tr,
            sep_t=sep_t,
            tw=tw,
        )

    def forward(self, v, v_tilde, y, update_queue=True, current_epoch=None, total_epochs=None):
        queue_v, queue_labels = self.queue.get()

        logits, _, q, loss, loss_class, loss_target = self.kcl(
            v=v,
            v_tilde=v_tilde,
            y=y,
            queue_v=queue_v,
            queue_labels=queue_labels,
            current_epoch=current_epoch,
            total_epochs=total_epochs,
        )

        if update_queue:
            with torch.no_grad():
                self.queue.enqueue(v, y)

        return {
            "loss": loss,
            "loss_kcl": loss_class,
            "loss_tsc": loss_target,
            "logits": logits,
            "embeddings": q,
        }


class TSCQueue(nn.Module):
    """
    TSCë¥¼ ìœ„í•œ FIFO Queue
    - Momentum update ë°©ì‹ì€ ì•„ë‹˜...
    - ê³¼ê±° ë°°ì¹˜ì˜ ì„ë² ë”©ê³¼ ë¼ë²¨ì„ ì €ì¥í•˜ì—¬ ëŒ€ì¡°í•™ìŠµì˜ negative samples í™•ë³´
    """
    def __init__(self, embedding_dim, queue_size, device=None):
        super().__init__()
        self.queue_size = queue_size
        self.embedding_dim = embedding_dim

        # [queue_size, Dim=128]
        self.register_buffer("queue_embeds", F.normalize(torch.randn(queue_size, embedding_dim), dim=1))
        self.register_buffer("queue_labels", torch.full((queue_size,), -100, dtype=torch.long)) # ê²°ì¸¡ ë¼ë²¨ë„ ì•„ë‹Œ -100ì„ ì‚¬ìš©í•¨.
        self.register_buffer("queue_ptr", torch.zeros(1, dtype=torch.long))

    @torch.no_grad()
    def enqueue(self, embeddings, labels):
        """
        embeddings: [B, D]
        labels: [B]
        - ê³¼ê±° ìƒ˜í”Œë“¤ì˜ featureì™€ labelì„ ì €ì¥í•´ì„œ TSC Lossì˜ ë¶„ëª¨ V_ië¥¼ êµ¬ì„±í•¨.
        1. ìƒˆ ì„ë² ë”©ì„ normalizeí•˜ì—¬ unit sphereì— ìœ„ì¹˜ì‹œí‚´.
        2. queue_ptr ìœ„ì¹˜ë¶€í„° ìˆœì„œëŒ€ë¡œ ë®ì–´ì”€.
        3. Queue ëì„ ë„˜ìœ¼ë©´ ì•ìœ¼ë¡œ ëŒì•„ì˜´ (circular buffer)
        4. Pointerë¥¼ ë‹¤ìŒ ìœ„ì¹˜ë¡œ ì—…ë°ì´íŠ¸í•¨.
        """
        z = F.normalize(embeddings.detach(), dim=1) # no-grad
        labels = labels.detach().long()

        B = z.size(0)                     # ëª¨ë¸ì— ë“¤ì–´ì˜¨ ë°°ì¹˜ í¬ê¸°
        ptr = int(self.queue_ptr.item())  # í˜„ì¬ queueì— ì“°ê¸° ì‹œì‘í•  ìœ„ì¹˜
        Q = self.queue_size               # ì „ì²´ queue í¬ê¸°

        # circular enqueue
        if ptr + B <= Q:
            # í•œ ë²ˆì— ë‹¤ ë“¤ì–´ê°€ëŠ” ê²½ìš°
            self.queue_embeds[ptr:ptr + B] = z
            self.queue_labels[ptr:ptr + B] = labels

        else:
            # queue sizeë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš° (ì²« ë²ˆì§¸ ë¹¼ê³ ëŠ” ì „ë¶€ elseêµ¬ë¬¸ì„ í†µí•´ ì—…ë°ì´íŠ¸ë  ê²ƒì„.)
            first = Q - ptr
            # ì¼ë‹¨ ì”ì—¬ queue ëê¹Œì§€ ì±„ìš°ê¸°
            self.queue_embeds[ptr:] = z[:first]
            self.queue_labels[ptr:] = labels[:first]
            # ë‚¨ì€ ê²ƒì€ ì•ë¶€í„° ì±„ìš°ê¸°
            self.queue_embeds[:B - first] = z[first:]
            self.queue_labels[:B - first] = labels[first:]

        self.queue_ptr[0] = (ptr + B) % Q # FIFO / í¬ì¸í„°ë„ ì—…ë°ì´íŠ¸í•¨.

    def get(self):
        return self.queue_embeds, self.queue_labels


class KCL(nn.Module):
    """
    1. KCL: Queueì™€ Kë¥¼ ì‚¬ìš©í•´ì„œ ìƒ˜í”Œë§í–ˆì„ ë¿ supervised contrastive learningê³¼ ê°™ì€ ê°œë…
    - Anchorì™€ ê°™ì€ í´ë˜ìŠ¤ ìƒ˜í”Œ = positive
    - Anchorì™€ ë‹¤ë¥¸ í´ë˜ìŠ¤ ìƒ˜í”Œ = negative
    - Queueì—ì„œ Kê°œì˜ positiveë§Œ ìƒ˜í”Œë§í•˜ë©°, ì´ë¥¼ í†µí•´ í´ë˜ìŠ¤ë³„ imbalanceë¥¼ í•´ì†Œí•¨.
    - ê·¸ëŸ°ë° ì´ë¯¸ì§€ì™€ ë‹¤ë¥´ê²Œ í´ë˜ìŠ¤ë³„ ì„ë² ë”© ê°„ ì°¨ì´ê°€ í¬ì§€ ì•Šì€ ìš°ë¦¬ ì—°êµ¬ì—ëŠ” ë³´ì™„ì´ í•„ìš”í•´ë³´ì„.
        
    2. TSC: Target embeddingì„ ì‚¬ìš©í•˜ì—¬ í• ë‹¹ëœ Targetìœ¼ë¡œ í´ë˜ìŠ¤ë³„ ì„ë² ë”©ì„ ëŒì–´ë‹¹ê¹€.
    - ê° í´ë˜ìŠ¤ë§ˆë‹¤ optimal target embedding ì‚¬ì „ ì •ì˜
    - Class centroid â†” Target embedding Hungarian algorithm based matching
    - Targetì„ ì¶”ê°€ positiveë¡œ ì‚¬ìš©í•˜ì—¬ centroidë¡œ ìˆ˜ë ´ ìœ ë„ (ì „ì—­ì ìœ¼ë¡œ ë°€ì–´ë‚´ëŠ” íš¨ê³¼ë„ ìˆìŒ.)
    """
    def __init__(self,
        dim=128,            # projection head í›„ ì„ë² ë”© ì°¨ì›
        K=8192,             # queue size
        m=0.999,            # momentum encoder update ratio
        T=0.07,             # temperature
        num_positive=0,     # anchor ë‹¹ positive sampling ê°œìˆ˜ (K)
        targeted=False,     # target-based contrastive loss ì‚¬ìš© ì—¬ë¶€
        tr=20, 
        sep_t=True, 
        tw=1                # target loss ê°€ì¤‘ì¹˜ (lambda)
    ):
        super(KCL, self).__init__()

        self.K = K                          # queue size
        self.m = m                          
        self.T = T                          # temperature
        self.num_positive = num_positive    # anchor ë‹¹ positive sampling ê°œìˆ˜ (K)
        self.n_cls = 3                      # The number of classes
        self.targeted = targeted            # TSC ì‚¬ìš© ì—¬ë¶€
        self.tr = tr                        # Target repeat íšŸìˆ˜
        self.sep_t = sep_t
        self.tw = tw                        # target-loss weight

        # ========================== optimal target embedding ==========================
        optimal_target = np.load(OUTPUT_DIR + 'targets/optimal_target_{}_{}.npy'.format(self.n_cls, dim)) # [n_cls, dim]
        optimal_target_order = np.arange(self.n_cls)
        target_repeat = tr * np.ones(self.n_cls)
        """
        ë¶„ëª¨ê°€ ì´ë¯¸ aug pos 1ê°œ, K (queue), T_n (targets)ë¡œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ë°, ì´ë•Œ queue 8192ê°œì— targetì´ 3ê°œë¼ë©´ targetì€ ê±°ì˜ ë¬´ì‹œë  ìˆ˜ ë°–ì— ì—†ëŠ” êµ¬ì¡°ì„.
        - ë”°ë¼ì„œ targetì„ trë°°í•˜ì—¬ ë¶„ëª¨ ë‚´ì—ì„œ targetì˜ ì˜í–¥ë ¥ì„ ë†’ì„.
        - ì¦‰, targetì´ softmax ë¶„ëª¨ì—ì„œ ì‚¬ë¼ì§€ì§€ ì•Šë„ë¡ ë¶„ëª¨ weightë¥¼ ë§ì¶”ëŠ” ì—­í• .
        - ì½”ë“œì— ë¬¸ì œê°€ ì—†ë‹¤ë©´, trì— ë”°ë¥¸ ì‹¤í—˜ì´ í•„ìš”í•¨ [10, 100, 1000]
        - (ì¶”ê°€) trì„ ê³¼í•˜ê²Œ ì„¤ì •í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ì¤‘ìš”í•  ê²ƒì„ ë³´ì„.
        """
        optimal_target = torch.Tensor(optimal_target).float()
        target_repeat = torch.Tensor(target_repeat).long()
        optimal_target = torch.cat([optimal_target[i:i + 1, :].repeat(target_repeat[i], 1) for i in range(len(target_repeat))], dim=0)
        target_labels = torch.cat([torch.Tensor([optimal_target_order[i]]).repeat(target_repeat[i]) for i in range(len(target_repeat))], dim=0).long().unsqueeze(-1)

        self.register_buffer("optimal_target", optimal_target)
        self.register_buffer("optimal_target_unique", optimal_target[::self.tr, :].contiguous().transpose(0, 1))
        self.register_buffer("target_labels", target_labels)

        # Initialize class centroids (for EMA update during training)
        self.register_buffer("class_centroid", torch.randn(self.n_cls, dim))

        # Target Diagnosis
        print(f"\n{'='*80}")
        print(f"ğŸ¯ TSC Target Embeddings Loaded")
        print(f"   File: optimal_target_{self.n_cls}_{dim}.npy")
        print(f"   Shape after repeat (tr={tr}): {self.optimal_target.shape}")
        print(f"   Expected: [{self.n_cls * tr}, {dim}] = [{self.n_cls}*{tr}, {dim}]")
        print(f"   Target labels shape: {self.target_labels.shape}")
        print(f"   Unique targets shape: {self.optimal_target_unique.shape}")
        print(f"   Target embedding norms (first 3): {F.normalize(self.optimal_target[:3], dim=1).norm(dim=1).cpu().numpy()}")
        print(f"   First target sample (class 0): {self.optimal_target[0, :5].cpu().numpy()}")
        print(f"{'='*80}\n")

    def forward(
        self,
        v,                      # projection head output
        v_tilde,                # augmentation(positive pair)
        y,                      # labels
        queue_v,
        queue_labels,
        current_epoch=None,     # Current epoch (for staged activation)
        total_epochs=None,      # Total epochs (for staged activation)
    ):

        device = v.device
        B, D = v.shape
        q = F.normalize(v, dim=1)         # [B, D] - í˜„ì¬ ë°°ì¹˜ì˜ anchor (query view)
        k = F.normalize(v_tilde, dim=1)   # [B, D] - positive view (key view)

        qneg = F.normalize(queue_v.detach(), dim=1)  # [Q, D] - queueëŠ” í•™ìŠµ ëŒ€ìƒì´ ì•„ë‹ˆë¯€ë¡œ lossê°€ queueë¥¼ í†µí•´ ê³¼ê±° ì„ë² ë”©ìœ¼ë¡œ ì—­ì „íŒŒë˜ëŠ” ê²ƒì„ ì°¨ë‹¨í•¨.
        qlab = queue_labels.detach().long()          # [Q]    - queueì— ì €ì¥ëœ ì„ë² ë”©ì˜ í´ë˜ìŠ¤ ë¼ë²¨

        # ì‚¬ì „ì— ê³„ì‚°í•´ë‘” 128ì°¨ì›ì˜ target loadí•¨.
        use_target = self.targeted
        if current_epoch is not None and total_epochs is not None:
            prev_use_target = hasattr(self, '_prev_use_target') and self._prev_use_target
            use_target = use_target and (current_epoch >= total_epochs // 2)

            if use_target and not prev_use_target:
                valid_queue_labels = (queue_labels != -100).sum().item()
                queue_fill_ratio = valid_queue_labels / self.K * 100

                print(f"\n{'='*80}")
                print(f"ğŸ¯ TSC (Targeted Supervised Contrastive) ACTIVATED!")
                print(f"   Epoch: {current_epoch + 1}/{total_epochs}")
                print(f"   Queue size: {self.K}")
                print(f"   Queue filled: {valid_queue_labels}/{self.K} ({queue_fill_ratio:.1f}%)")
                print(f"   Temperature: {self.T}")
                print(f"   Target weight (tw): {self.tw}")

                # Centroidsê°€ Assigned targetì— ì–¼ë§Œí¼ ì˜ ë”°ë¼ê°€ëŠ”ì§€ ì¸¡ì •í•¨.
                print(f"\n   ğŸ“Š Centroid-Target Status:")
                tgt_unique = F.normalize(self.optimal_target_unique.t(), dim=1).cpu()  # [n_cls, D]
                cent = F.normalize(self.class_centroid, dim=1).cpu()  # [n_cls, D]
                for c in range(self.n_cls):
                    dist = (cent[c] - tgt_unique[c]).norm().item()
                    print(f"      Class {c}: centroid-target distance = {dist:.4f}")

                print(f"{'='*80}\n")

            self._prev_use_target = use_target

        # compute logits
        l_pos = torch.einsum("bd,bd->b", q, k).unsqueeze(1) # [B, 1] - anchorì™€ self positive ê°„ì˜ ìœ ì‚¬ë„ (logit 0ë²ˆìœ¼ë¡œ ê³ ì •í•¨)
        l_neg_queue = torch.matmul(q, qneg.t())             # [B, K] - anchor q_iì™€ queueì— ì €ì¥ëœ ëª¨ë“  ê³¼ê±° ì„ë² ë”©ê³¼ì˜ ìœ ì‚¬ë„

        # ì¦ê°•ì„ í†µí•œ ì„ë² ë”©ì˜ ë³€í™” ì¸¡ì •í•¨.
        if not hasattr(self, '_debug_printed'):
            print(f"\n[KCL DEBUG] Positive pair similarity (l_pos):")
            print(f"  Mean: {l_pos.mean().item():.4f}")
            print(f"  Min: {l_pos.min().item():.4f}")
            print(f"  Max: {l_pos.max().item():.4f}")
            self._debug_printed = True

        if use_target:
            tgt = F.normalize(self.optimal_target.to(device), dim=1)  # [Tn, D]    - [n_cls, D]ì§œë¦¬ ì›í˜• targetì„ ê° í´ë˜ìŠ¤ë§ˆë‹¤ trë²ˆ repeatí•´ì„œ ë§Œë“¦.
            l_neg_tgt = torch.matmul(q, tgt.t())                      # [B, Tn]
            l_neg = torch.cat([l_neg_queue, l_neg_tgt], dim=1)        # [B, K+Tn]
        else:
            l_neg = l_neg_queue                             # [B, K]

        logits = torch.cat([l_pos, l_neg], dim=1) # [B, 1+K(+Tn)]
        logits = logits / self.T
        labels_ce = torch.zeros(B, dtype=torch.long, device=device)

        # same-class positive mask ë§Œë“¤ê¸°
        y = y.view(-1, 1).long()
        qlab_row = qlab.view(1, -1)

        if use_target:
            target_labels = self.target_labels.to(device).t().contiguous()  # [1,Tn]

            # queue ë‚´ë¶€ ê°™ì€ í´ë˜ìŠ¤ ìƒ˜í”Œì„ 1ì°¨ maskë¡œ ì •ì˜í•¨
            # - targetì€ ì•„ì§ ì „ë¶€ 0ìœ¼ë¡œ ë´„.
            mask_queue = (y == qlab_row).float()                                    # [B,K]
            mask_target = torch.zeros((B, target_labels.size(1)), device=device)    # [B,Tn]
            mask = torch.cat([mask_queue, mask_target], dim=1)                      # [B,K+Tn]

            #  class centroid â†” target assignment
            """
            - Class centroidê°€ ì–´ë–¤ targetìœ¼ë¡œ ìˆ˜ë ´í•´ì•¼ í•˜ëŠ”ì§€ ê²°ì •í•¨.
            - Class centroidì™€ target ê°„ì˜ similarityë¥¼ ìµœëŒ€í™”í•˜ë„ë¡ ë§¤ì¹­í•¨.

            Flow:
                1. Class centroidë¥¼ EMA ë°©ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•¨.
                2. Centroid-Target Similarity matrix ê³„ì‚°í•¨ [n_cls, n_cls]
                3. í—ê°€ë¦¬ì•ˆ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìµœì  ë§¤ì¹­ ì°¾ê¸°
                4. ë§¤ì¹­ëœ targetì„ í•´ë‹¹ classì˜ positiveë¡œ ì¶”ê°€í•¨.
            """
            with torch.no_grad():
                feat_all = q.detach()

                # ==================== Centroid Update (EMA) ====================
                centroid_updates = {}
                for one_label in torch.unique(y):
                    one_label_int = int(one_label.item())
                    
                    if one_label_int < 0 or one_label_int >= self.n_cls: # Skip invalid labels (-1 or out of range)
                        continue

                    sel = (y[:, 0] == one_label_int)
                    if sel.any():
                        centroid_old = self.class_centroid[one_label_int].clone()
                        centroid_batch = F.normalize(feat_all[sel].mean(dim=0), dim=0)  # [D]
                        self.class_centroid[one_label_int] = F.normalize(0.9 * self.class_centroid[one_label_int].to(device) + 0.1 * centroid_batch, dim=0)

                        # Track centroid movement
                        centroid_new = self.class_centroid[one_label_int]
                        movement = (centroid_new - centroid_old.to(device)).norm().item()
                        centroid_updates[one_label_int] = (sel.sum().item(), movement)

                # DEBUG: Print centroid updates (first time TSC activates)
                if not hasattr(self, '_centroid_logged') and centroid_updates:
                    print(f"\nğŸ“Š Centroid Update (first TSC batch):")
                    for cls, (count, movement) in centroid_updates.items():
                        print(f"   Class {cls}: {count} samples, centroid moved {movement:.6f}")
                    self._centroid_logged = True

                # ==================== Hungarian Matching ====================
                cent = F.normalize(self.class_centroid.to(device), dim=1)      # [n_cls, D]
                otu = self.optimal_target_unique.to(device)                    # [D, n_cls]
                dist = torch.matmul(cent, otu).detach().float().cpu().numpy()  # [n_cls, n_cls] (similarity) - cast to float32 before numpy
                row_ind, col_ind = linear_sum_assignment(-dist)                # maximize similarity

                if not hasattr(self, '_hungarian_logged') or not self._hungarian_logged:
                    print(f"\n{'='*80}")
                    print(f"ğŸ” Hungarian Matching Result:")
                    print(f"   Centroid-Target Similarity Matrix:")
                    for i in range(self.n_cls):
                        print(f"   Centroid {i}: {dist[i]}")
                    print(f"   Assignment: {list(zip(row_ind, col_ind))}")
                    for cls, tgt_idx in zip(row_ind, col_ind):
                        print(f"   Class {cls} â†’ Target {tgt_idx} (similarity: {dist[cls, tgt_idx]:.4f})")
                    print(f"   Centroid norms: {cent.norm(dim=1).cpu().numpy()}")
                    print(f"{'='*80}\n")
                    self._hungarian_logged = True

                # ==================== Matched Targetì„ Positiveë¡œ ì¶”ê°€ ====================
                for cls, tgt_idx in zip(row_ind, col_ind):
                    cls = int(cls)
                    sel = (y[:, 0] == cls)

                    if not sel.any():
                        continue

                    t_indices = torch.arange(tgt_idx * self.tr, tgt_idx * self.tr + self.tr, device=device)

                    # targetì´ matching positivieë¡œ ì´ ì‹œì ë¶€í„° ì§€ì •ë¨
                    sel_indices = torch.where(sel)[0]  # [N_sel]
                    mask[sel_indices[:, None], qlab.numel() + t_indices[None, :]] = 1.0

            if self.sep_t:
                mask_target_only = mask.clone()
                mask_target_only[:, :qlab.numel()] = 0.0
                mask_class_only = mask.clone()
                mask_class_only[:, qlab.numel():] = 0.0
            else:
                mask_class_only = mask
                mask_target_only = mask
        else:
            mask = (y == qlab_row).float()
            mask_class_only = mask
            mask_target_only = mask

        mask_pos_view = torch.zeros_like(mask)          # [B,K(+Tn)]

        # ==================== KCLì˜ K-positive ìƒ˜í”Œë§ ====================
        """
        - ì¼ì¢…ì˜ hard negative mining ê°•í™” ë°©ì‹ì„.
        - ëœë¤ìƒ˜í”Œë§ê³¼ ë‹¤ë¥´ê²Œ ê°€ì¥ íš¨ê³¼ì ì¸ K ìƒ˜í”Œë§ ë°©ë²•ì€ ì—†ì„ê¹Œ?
        """
        if self.num_positive > 0:
            work_mask = mask.clone()
            for iteration in range(self.num_positive):
                all_pos = work_mask.view(-1).nonzero().view(-1)

                # Early exit: positiveê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì¢…ë£Œ (ë³´í˜¸ì¥ì¹˜ì¸ë° ì‚¬ì‹¤ìƒ ì‘ë™ ì•ˆí•¨.)
                if all_pos.numel() == 0:          
                    break

                num_pos = work_mask.sum(1)                                   # ê° anchorì˜ positive ê°œìˆ˜                   
                num_pos_cum = num_pos.cumsum(0).roll(1)
                num_pos_cum[0] = 0

                rand = torch.rand(B, device=device)                          # ê° anchorì—ì„œ ëœë¤í•˜ê²Œ í•˜ë‚˜ì”© ìƒ˜í”Œë§
                idxs = ((rand * num_pos).floor() + num_pos_cum).long()
                valid = (num_pos > 0)                                        # Positiveê°€ ìˆëŠ” anchorë§Œ ì²˜ë¦¬
                idxs = idxs[valid]

                if idxs.numel() > 0:
                    idxs = idxs.clamp(0, all_pos.numel() - 1)
                    sampled = all_pos[idxs]
                    mask_pos_view.view(-1)[sampled] = 1.0
                    work_mask.view(-1)[sampled] = 0.0
        else:
            # K-sampling ë¹„í™œì„±í™” - ëª¨ë“  positive ì‚¬ìš©
            mask_pos_view = mask.clone()

        # ìµœì¢… mask êµ¬ì„± ê³¼ì •
        if use_target and self.sep_t:
            mask_pos_view_class = (mask_pos_view * (mask_class_only > 0).float())
            mask_pos_view_target = (mask_target_only > 0).float()
            denom_mask = mask_pos_view + (mask_target_only > 0).float()
        else:
            mask_pos_view_class = mask_pos_view.clone()
            mask_pos_view_target = torch.zeros_like(mask_pos_view)
            denom_mask = mask_pos_view

        ones_pos = torch.ones((B, 1), device=device)
        zeros_pos = torch.zeros((B, 1), device=device)

        mask_all = torch.cat([ones_pos, denom_mask], dim=1)  # [B, 1+K(+Tn)]
        mask_class = torch.cat([ones_pos, mask_pos_view_class], dim=1)
        mask_target = torch.cat([zeros_pos, mask_pos_view_target], dim=1)

        # ==================== Loss ê³„ì‚° ====================
        log_prob = F.log_softmax(logits, dim=1)
        denom = mask_all.sum(1).clamp_min(1.0)

        loss_class = -((mask_class * log_prob).sum(1) / denom).mean()
        loss_target = -((mask_target * log_prob).sum(1) / denom).mean()

        loss_target = loss_target * self.tw
        loss = loss_class + loss_target

        return logits, labels_ce, q, loss, loss_class, loss_target

################################################################################################################################
################################################################################################################################

# Global Loss
## Supervised Contrastive Loss (Single-View)
class SupConLoss(nn.Module):
    def __init__(self):
        super(SupConLoss, self).__init__()

    def forward(self, embeddings, labels, window_mask, temperature):
        device = embeddings.device
        D = embeddings.shape[-1]

        # 1) Flatten windows
        feat_flat = embeddings.reshape(-1, D)           # [B*W, D]
        lab_flat = labels.view(-1)                      # [B*W]
        mask_flat = window_mask.view(-1).bool()         # [B*W]

        # 2) Valid window filtering (exclude unlabeled and padded)
        valid = mask_flat & (lab_flat != -1)

        if valid.sum() == 0:
            return torch.tensor(0.0, device=device, requires_grad=True)

        features = feat_flat[valid]     # [N, D]
        labels_valid = lab_flat[valid]  # [N]

        # 3) L2 normalize (Necessary in Contrastive Learning)
        features = F.normalize(features, p=2, dim=-1)

        N = features.shape[0]
        if N < 2:
            return torch.tensor(0.0, device=device, requires_grad=True)

        # 4) Compute similarity matrix
        logits = torch.div(features @ features.T, temperature)  # [N, N]

        # 5) Create positive mask (same label)
        labels_row = labels_valid.view(-1, 1)
        labels_col = labels_valid.view(1, -1)
        pos_mask = (labels_row == labels_col).float()  # [N, N]

        # 6) Remove self-contrast (diagonal)
        logits_mask = torch.ones_like(pos_mask)
        diag_idx = torch.arange(N, device=device)
        logits_mask[diag_idx, diag_idx] = 0
        pos_mask = pos_mask * logits_mask  # Remove diagonal from positive mask

        # 7) Mask out invalid positions in logits
        logits_masked = logits + (1 - logits_mask) * -1e9

        # 8) Compute log probability
        log_prob = logits - torch.logsumexp(logits_masked, dim=1, keepdim=True)

        # 9) Compute mean of log-likelihood over positive pairs
        pos_per_anchor = pos_mask.sum(1).clamp(min=1e-6)
        mean_log_prob_pos = (pos_mask * log_prob).sum(1) / pos_per_anchor
        loss = -mean_log_prob_pos.mean()

        return loss

#############################################################################################################
#############################################################################################################
# Grave of codes

# Time-aware pull loss
"""
- Anchor: Window itself
- Positive: ê°™ì€ í™˜ìì˜ ë‹¤ë¥¸ ì‹œê°„ window
- Pull strength = ì‹œê°„ ê±°ë¦¬ì˜ í•¨ìˆ˜

z(t) --strong pull--> z(t+1)
z(t) --weak pull--> z(t+5)
- ì‹œê°„ ì¶•ì—ì„œì˜ êµ­ì†Œ ì´ì›ƒì„ í•™ìŠµí•˜ëŠ” loss
"""
# def time_aware_pull_loss(
#     z,                 # [N, D]
#     t_local,           # [N]
#     stay_local,        # [N]
#     temperature=0.1,
#     beta=1.0,
#     very_neg=-1e9
# ):
#     """
#     Single-view time-aware pull loss.
#     Encourages temporally nearby windows of the same patient to cluster.
#     """
#     device = z.device
#     N = z.size(0)

#     z_norm = F.normalize(z, p=2, dim=-1) # L2 Normalize
#     sim = torch.matmul(z_norm, z_norm.T) / temperature  # [N, N]

#     # Remove self-contrast (Diagonal)
#     mask_self = torch.eye(N, dtype=torch.bool, device=device)
#     sim = sim.masked_fill(mask_self, very_neg)

#     # Same-patient & different-time mask
#     same_patient = stay_local.unsqueeze(1) == stay_local.unsqueeze(0)
#     time_dist = (t_local.unsqueeze(1) - t_local.unsqueeze(0)).abs()
#     mask_pos = same_patient & (time_dist > 0)

#     # Time-aware weights
#     w = torch.zeros_like(sim) 
#     w[mask_pos] = (1.0 / (beta + time_dist[mask_pos])).to(w.dtype)
#     w = w / (w.sum(dim=1, keepdim=True) + 1e-8)

#     # Weighted InfoNCE
#     log_prob = F.log_softmax(sim, dim=1)
#     loss = -(w * log_prob).sum(dim=1).mean()

#     return loss


# # Local Loss
# ## Margin ë‚˜ëˆ ì„œ ì‹¤í—˜ ìˆ˜í–‰[0.3, 0.5, 0.8]
# def local_temporal_loss(z, stay_ids, margin=0.5):
#     """
#     Local temporal smoothness loss: pull nearby time windows closer if they're within margin.
#     L = -Î£ min(0, ||z_i - z_j||â‚‚ - margin) = Î£ max(0, margin - ||z_i - z_j||â‚‚)
#     """
#     device = z.device

#     # Patient-level filter
#     mask = stay_ids[1:] == stay_ids[:-1]

#     if not mask.any():
#         return torch.tensor(0.0, device=device)

#     z_prev = z[:-1][mask]
#     z_next = z[1:][mask]

#     dist = torch.norm(z_prev - z_next, dim=1)

#     # -Î£ min(0, dist - margin) = Î£ max(0, margin - dist)
#     loss = torch.relu(margin - dist).mean()

#     return loss


# # Time-series embedding level Loss
# class TSReconstructionLoss(nn.Module):
#     def __init__(self, d_model=512, mask_ratio=0.15):
#         super().__init__()
#         self.mask_ratio = mask_ratio
#         self.d_model = d_model

#         self.reconstruction_head = nn.Sequential(
#             nn.Linear(d_model, d_model),
#             nn.GELU(),
#             nn.LayerNorm(d_model),
#             nn.Linear(d_model, d_model)
#         )

#         print(f"[TSReconstructionLoss] Initialized with d_model={d_model}, mask_ratio={mask_ratio}")

#     def forward(self, ts_encoded, seq_valid_mask):
#         """
#         Args:
#             ts_encoded: [B*W, T, 512] - TS encoder output (before QKV adapter)
#             seq_valid_mask: [B, W, T] - 1 for valid timesteps, 0 for padding
#         """
#         device = ts_encoded.device
#         BW, T, D = ts_encoded.shape

#         # Reshape seq_valid_mask from [B, W, T] to [B*W, T]
#         B = seq_valid_mask.size(0)
#         W = seq_valid_mask.size(1)
#         seq_valid_mask = seq_valid_mask.view(B * W, T)  # [B*W, T]

#         # Only process windows with valid timesteps
#         valid_windows = seq_valid_mask.sum(dim=1) > 0  # [B*W]
#         if valid_windows.sum() == 0:
#             return torch.tensor(0.0, device=device, requires_grad=True)

#         ts_valid = ts_encoded[valid_windows]        # [N_valid, T, D]
#         mask_valid = seq_valid_mask[valid_windows]  # [N_valid, T]

#         N_valid = ts_valid.size(0)

#         # Create random mask for valid timesteps only
#         # mask_prob: [N_valid, T], True=mask
#         rand = torch.rand(N_valid, T, device=device)
#         mask_prob = (rand < self.mask_ratio) & mask_valid.bool()  # Only mask valid positions

#         # Ensure at least 1 valid timestep is NOT masked per window
#         valid_count = mask_valid.sum(dim=1)         # [N_valid]
#         mask_count = mask_prob.sum(dim=1)           # [N_valid]
#         all_masked = mask_count >= valid_count      # [N_valid]

#         # Masking correction condition
#         if all_masked.any():
#             # Unmask the first valid timestep in windows that are fully masked
#             for i in all_masked.nonzero(as_tuple=False).squeeze(1):
#                 first_valid_idx = mask_valid[i].nonzero(as_tuple=False)[0, 0]
#                 mask_prob[i, first_valid_idx] = False

#         # Original embeddings - Targets for reconstruction (No gradient flow)
#         targets = ts_valid.clone().detach()  # [N_valid, T, D]

#         # Mask embeddings
#         masked_embeddings = ts_valid.clone()
#         masked_embeddings[mask_prob] = 0.0

#         # Reconstruct masked embeddings
#         reconstructed = self.reconstruction_head(masked_embeddings)                     # [N_valid, T, D]

#         # MSE loss on masked positions
#         loss_mask = mask_prob  # [N_valid, T]
#         if loss_mask.sum() == 0:
#             return torch.tensor(0.0, device=device, requires_grad=True)
#         diff = (reconstructed - targets) ** 2                                           # [N_valid, T, D]
#         loss = (diff * loss_mask.unsqueeze(-1)).sum() / (loss_mask.sum() * D + 1e-8)

#         return loss


##############################################################################################################
##############################################################################################################
# # Unsupervised Contrastive Learning (UCL)
# class UnsupervisedContrastiveLoss(nn.Module):
#     """
#     Modular unsupervised contrastive learning framework.
#     ucl_components (dict): loss component weights + hyperparameters
#     """
#     def __init__(self, ucl_components):
#         super().__init__()
#         self.very_neg = -1e9
#         self.params = ucl_components

#         print(f"[UCL] Initialized with params: {self.params}")

#     def forward(self, cl_embeddings, time_indices, stay_ids, window_mask, temperature, prototypes=None, density=None):
#         device = cl_embeddings.device
#         B, V, W, D = cl_embeddings.shape

#         cl_flat = cl_embeddings.permute(0, 2, 1, 3).reshape(-1, V, D)       # [B*W, V, D]
#         t_flat = time_indices.view(-1)                                      # [B*W]
#         stay_flat = stay_ids.unsqueeze(1).repeat(1, W).view(-1)             # [B*W]
#         m_flat = window_mask.view(-1).bool()                                # [B*W]

#         z_local = cl_flat[m_flat]                                           # [N_local, V, D]
#         t_local = t_flat[m_flat]                                            # [N_local]
#         stay_local = stay_flat[m_flat]                                      # [N_local]

#         N = z_local.size(0)
#         if N < 2:
#             return torch.tensor(0.0, device=device, requires_grad=True)

#         z_anchor = z_local[:, 0, :]                             # [N, D] - Original view
#         z_aug = z_local[:, 1, :] if V > 1 else z_anchor         # [N, D] - Augmented view

#         total_loss = torch.tensor(0.0, device=device)
#         weights_components = {'standard_infonce', 'time_aware_pull', 'prototypical'}

#         for key, value in self.params.items():
#             if key not in weights_components:
#                 continue

#             weight = value
#             if weight == 0.0:
#                 continue

#             if key == 'standard_infonce':
#                 loss = self._standard_infonce_loss(
#                     z_anchor, z_aug, temperature, device
#                 )
#             elif key == 'time_aware_pull':
#                 loss = self._time_aware_pull_loss(
#                     z_anchor, z_aug, t_local, stay_local, temperature, device
#                 )
#             elif key == 'prototypical':
#                 if prototypes is not None and density is not None:
#                     loss = self._prototypical_loss(
#                         z_anchor, prototypes, density, temperature, device
#                     )
#                 else:
#                     # Prototypes not initialized yet (warmup phase)
#                     loss = torch.tensor(0.0, device=device)

#             total_loss += weight * loss

#         return total_loss
    
#     def _standard_infonce_loss(self, z_anchor, z_aug, temperature, device):
#         """
#         Standard InfoNCE loss
#         Each anchor's positive is its augmented view; all others are negatives.
#         """
#         N = z_anchor.size(0)

#         sim_matrix = torch.matmul(z_anchor, z_aug.T) / temperature 
#         labels = torch.arange(N, device=device)

#         loss = F.cross_entropy(sim_matrix, labels)
#         return loss

    # def _time_aware_pull_loss(self, z_anchor, z_aug, t_local, stay_local, temperature, device):
    #     """
    #     Time-aware InfoNCE loss for medical time series.
    #     Positive pairs are weighted by temporal proximity within the same patient.
    #     """
    #     N = z_anchor.size(0)

    #     sim = torch.matmul(z_anchor, z_aug.T) / temperature  # [N, N]

    #     # Mask diagonal (self-contrast)
    #     mask_self = torch.eye(N, dtype=torch.bool, device=device)
    #     sim = sim.masked_fill(mask_self, self.very_neg)

    #     # Identify positive pairs (same patient, different time)
    #     same_patient = stay_local.unsqueeze(1) == stay_local.unsqueeze(0)  # [N, N]
    #     time_dist = (t_local.unsqueeze(1) - t_local.unsqueeze(0)).abs()  # [N, N]
    #     mask_pos = same_patient & (time_dist > 0)  # Exclude self

    #     # Compute time-aware weights
    #     beta = self.params['beta']
    #     w = torch.zeros_like(sim)
    #     w[mask_pos] = (1.0 / (beta + time_dist[mask_pos])).to(w.dtype)
    #     w = w / (w.sum(dim=1, keepdim=True) + 1e-8)  # Normalize

    #     # Weighted InfoNCE
    #     loss = -(w * F.log_softmax(sim, dim=1)).sum(dim=1).mean()
    #     return loss

#     def _prototypical_loss(self, z_anchor, prototypes, density, temperature, device):
#         """
#         Prototypical contrastive loss: Each sample is contrasted against prototype centroids with density-based temperature scaling.

#         z_anchor: query embeddings                              # [N, D]
#         prototypes: prototype vectors (K = num_prototypes)      # [K, D]
#         density: temperature scaling factor per prototype       # [K]
#         temperature: base temperature
#         """

#         # Compute similarity: z_anchor vs all prototypes [N, K]
#         sim = torch.matmul(z_anchor, prototypes.T) / temperature

#         # Assign each sample to nearest prototype (pseudo-label)
#         proto_labels = torch.argmax(sim, dim=1)

#         # Density-based dynamic temperature scaling
#         sim = sim / density.unsqueeze(0)
#         loss = F.cross_entropy(sim, proto_labels)

#         return loss


# class PrototypeManager:
#     """
#     Manages prototypes for prototypical contrastive learning using faiss clustering.
#     Based on PCL (Prototypical Contrastive Learning) paper.
#     """
#     def __init__(self, num_prototypes=100, embedding_dim=256, temperature=0.1, device='cuda'):
#         self.num_prototypes = num_prototypes
#         self.embedding_dim = embedding_dim
#         self.temperature = temperature
#         self.device = device

#         # Prototypes (centroids)
#         self.prototypes = None
#         self.density = None  # Concentration estimation for each prototype
#         self.initialized = False
#         print(f"[PrototypeManager] Initialized with {num_prototypes} prototypes, dim={embedding_dim}")

#     @torch.no_grad()
#     def update_prototypes(self, features):
#         """
#         Update prototypes using K-means clustering on features.

#         Args:
#             features: [N, D] normalized embeddings from momentum encoder
#         """

#         features = features.cpu().numpy().astype('float32')
#         N, D = features.shape

#         if N < self.num_prototypes:
#             print(f"[PrototypeManager] Warning: {N} samples < {self.num_prototypes} prototypes. Skipping update.")
#             return

#         # Initialize faiss clustering
#         k = self.num_prototypes
#         clus = faiss.Clustering(D, k)
#         clus.verbose = False
#         clus.niter = 20
#         clus.nredo = 5
#         clus.max_points_per_centroid = 3000
#         clus.min_points_per_centroid = 50

#         # Use CPU for clustering to avoid CUBLAS errors
#         # CPU K-means is stable and fast enough for our use case (runs once per epoch)
#         index = faiss.IndexFlatL2(D)

#         print(f"[PrototypeManager] Running K-means on CPU with {N} samples, {k} clusters...")

#         # Run clustering
#         clus.train(features, index)

#         # Get cluster assignments and distances
#         D_dist, I = index.search(features, 1)  # [N, 1]
#         im2cluster = I.squeeze(1)  # [N]

#         # Get centroids
#         centroids = faiss.vector_to_array(clus.centroids).reshape(k, D)

#         # Compute density (concentration) for each cluster
#         Dcluster = [[] for _ in range(k)]
#         for idx, cluster_id in enumerate(im2cluster):
#             Dcluster[cluster_id].append(D_dist[idx][0])

#         density = np.zeros(k)
#         for i, dist_list in enumerate(Dcluster):
#             if len(dist_list) > 1:
#                 d = (np.asarray(dist_list) ** 0.5).mean() / np.log(len(dist_list) + 10)
#                 density[i] = d

#         # Handle clusters with single points
#         dmax = density.max() if density.max() > 0 else 1.0
#         for i, dist_list in enumerate(Dcluster):
#             if len(dist_list) <= 1:
#                 density[i] = dmax

#         # Clamp extreme values for stability
#         density = np.clip(density, np.percentile(density, 10), np.percentile(density, 90))
#         # Scale the mean to temperature
#         density = self.temperature * density / (density.mean() + 1e-8)

#         # Convert to torch tensors
#         self.prototypes = torch.tensor(centroids, dtype=torch.float32, device=self.device)
#         self.prototypes = F.normalize(self.prototypes, p=2, dim=1)
#         self.density = torch.tensor(density, dtype=torch.float32, device=self.device)

#         self.initialized = True
#         print(f"[PrototypeManager] Updated prototypes: {k} clusters, density range [{density.min():.4f}, {density.max():.4f}]")

#     def get_prototypes(self):
#         """Return current prototypes and density."""
#         if not self.initialized:
#             return None, None
#         return self.prototypes, self.density



##############################################################################################################
# temporal based push-pull mechanism
# class ConstrainttimeLoss(nn.Module):
#     def __init__(self, beta, margin, tau, pull_weight, push_weight, use_tau_cut=True):
#         super().__init__()
#         self.beta = beta
#         self.margin = margin
#         self.tau = tau
#         self.pull_w = pull_weight
#         self.push_w = push_weight
#         self.use_tau_cut = use_tau_cut

#     def forward(self, cl_embeddings, time_indices, batch_indices, window_mask, temperature, accelerator=None):
#         # if False:
#         device = cl_embeddings.device
#         B, V, W, D = cl_embeddings.shape
        
#         # All-gather from all GPUs for better contrastive learning
#         with timer("All-gather for UCL"):

#             cl_flat = cl_embeddings.permute(0, 2, 1, 3).reshape(-1, V, D)
#             t_flat  = time_indices.view(-1)                                # [B*W]
#             b_flat  = batch_indices.view(-1)                               # [B*W]
#             m_flat  = window_mask.view(-1).bool()                          # [B*W]

#             z_local = cl_flat[m_flat]                                      # [N_local, V, D]
#             t_local = t_flat[m_flat]                                       # [N_local]
#             b_local = b_flat[m_flat]                                       # [N_local]

#             if accelerator.num_processes > 1:
#                 world_size = torch.distributed.get_world_size()

#                 z_lists = [None] * world_size
#                 t_lists = [None] * world_size
#                 b_lists = [None] * world_size

#                 torch.distributed.all_gather_object(z_lists, z_local)
#                 torch.distributed.all_gather_object(t_lists, t_local)
#                 torch.distributed.all_gather_object(b_lists, b_local)

#                 z_all = torch.cat([z.to(cl_embeddings.device) for z in z_lists], dim=0)  # [Î£N, V, D]
#                 t_all = torch.cat([t.to(cl_embeddings.device) for t in t_lists], dim=0)  # [Î£N]
#                 b_all = torch.cat([b.to(cl_embeddings.device) for b in b_lists], dim=0)  # [Î£N]

#             else: 
#                 z_all, t_all, b_all = z_local, t_local, b_local

#         # Local anchor, Global contrast ë¶„ë¦¬
#         # Normalization already done in ProjectionHead, no need to repeat here
#         z_O_local = z_local[:, 0, :]                          # local original view (anchor)
#         z_A_all = z_all[:, 1, :]                              # global augmented view (contrast)
#         # z_A_local = z_local[:, 1, :]                        # local augmented view (anchor)
#         # z_O_all = z_all[:, 0, :]                            # global original view (contrast)

#         if z_O_local.numel() == 0:
#             print("[UCL DEBUG] No valid local features.")
#             print("cl_embeddings:", cl_embeddings)
#             return torch.tensor(0.0, device=device, requires_grad=False)
        
#         t_local = t_local
#         b_local = b_local
#         t_all = t_all
#         b_all = b_all

#         # ---------------------------------------------------------
#         # 1) Timeâ€‘aware Pull (InfoNCE + ê°€ì¤‘ì¹˜) - Local anchor vs Global contrast
#         # ---------------------------------------------------------
#         sim_OA = torch.matmul(z_O_local, z_A_all.T) / temperature  # [N_local, N_all]

#         time_dist = (t_local.unsqueeze(1) - t_all.unsqueeze(0)).abs()          # [N_local, N_all]
#         same_seq  = b_local.unsqueeze(1) == b_all.unsqueeze(0)                 # [N_local, N_all] (ê°™ì€ í™˜ì ì—¬ë¶€)

#         w = torch.zeros_like(sim_OA)
#         w_dtype = w.dtype
#         w[same_seq] = (1.0 / (self.beta + time_dist[same_seq].float())).to(w_dtype) # ì‹œê°„ ê±°ë¦¬ì— ë°˜ë¹„ë¡€í•˜ëŠ” ê°€ì¤‘ì¹˜
#         w = w / (w.sum(dim=1, keepdim=True) + 1e-8)              # normalize
#         pull_loss = - (w * F.log_softmax(sim_OA, dim=1)).sum(dim=1).mean()

#         # ---------------------------------------------------------
#         # 2) Centroidâ€‘based Push (sequence ranking) - Local anchor ê¸°ì¤€
#         # ---------------------------------------------------------
#         seq_ids = torch.unique(b_local)

#         centroids = []
#         intra_d = []

#         for sid in seq_ids:
#             idx = (b_local == sid).nonzero(as_tuple=False).squeeze(1)
#             z_seq = z_O_local[idx]           # [n_i, D] - local anchorë§Œ ì‚¬ìš©
#             c = z_seq.mean(dim=0)            # centroid
#             centroids.append(c)
#             intra_d.append(torch.norm(z_seq - c, dim=1).mean())

#         C = torch.stack(centroids)           # [S,D]
#         intra = torch.stack(intra_d)         # [S]
#         inter = torch.cdist(C, C, p=2)       # [S,S]

#         # Ï„â€‘cut: ì§€ë‚˜ì¹˜ê²Œ ë¹„ìŠ·í•œ ë‹¤ë¥¸â€‘í™˜ì ìŒ drop
#         if self.use_tau_cut:
#             # convert distâ†’cos for unit vec: cosÎ¸ = 1 - d^2 / 2
#             sim = 1.0 - inter.pow(2) / 2.0
#             keep_mask = sim < self.tau
#             inter = inter * keep_mask + 1e9 * (~keep_mask)  # 1e9 ensures no ranking loss

#         # ranking loss vectors
#         S = C.size(0)
#         if S < 2:
#             push_loss = cl_embeddings.new_tensor(0.0)
#             total = self.pull_w * pull_loss + self.push_w * push_loss
#             return total

#         else:
#             x1 = intra.repeat_interleave(S - 1)                 # [S*(S-1)]
#             # exclude diagonal for inter distances
#             off_diag_mask = ~torch.eye(S, dtype=torch.bool, device=device)
#             x2 = inter[off_diag_mask]
#             target = -torch.ones_like(x1)

#             push_loss = F.margin_ranking_loss(x1, x2, target, margin=self.margin)

#             total = self.pull_w * pull_loss + self.push_w * push_loss
#         return total